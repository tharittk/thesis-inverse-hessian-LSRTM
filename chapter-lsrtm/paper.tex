\title{Chain of operators: Experiments}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\relax\footnotetext{This work was done under the supervision of Dr. Sergey Fomel.}
\author{Tharit Tangkijwanichakul}
\label{ch:chapter-lsrtm}

\maketitle

\section{Zero-offset Experiments}
\inputdir{../chapter-lsrtm/pre}

\subsection{Chain as a Deconvolution Filter: Synthetic Marmousi data}
%

We test the idea of of using the chain of operators with Marmousi data \cite[]{versteeg1994}. The shot gather volume is shown in Figure \ref{fig:bshots45} and consists of 45 shots. The migration velocity is shown in Figure \ref{fig:velmig} which is derived from smoothing the stratigraphic slowness. Figure \ref{fig:bmig1} shows reverse-time migarted image using a finite-difference wave propagator. 

\plot{bshots45}{width=0.6\columnwidth}{Shot gathers}
\plot{velmig}{width=0.6\columnwidth}{Migration velocity for prestack migration}
\plot{bmig1}{width=0.6\columnwidth}{RTM Image}

%

After we obtain the sencond migrated image $\mathbf{m_2}$ by remodeling and remigartion exercise ($\mathbf{L^{T}L}$) to $\mathbf{m_1}$, we form the initial weights $\mathbf{W_0}$ by taking the square-root of smooth division $\mathbf{\frac{m_2}{m_1}}$ as mentioned earlier.

We run the chain solver to estimate $\mathbf{W}$ and $\mathbf{W_f}$ for different numbers of iterations. The residual is about 1.9 $\%$, 0.23 $\%$, 0.21 $\%$ after 2, 5, 10 iterations respectively.These weights are shown in Figure \ref{fig:iw,iw5,iw10} and \ref{fig:iwf,iwf5,iwf10}). Notice that the weights in space domain $\mathbf{W^{1}}$does not change much after more iterations, contrasting to weights in frequency domain $\mathbf{W_f^{1}}$

\multiplot{3}{iw,iw5,iw10}{width=0.48\columnwidth}{$\mathbf{W^{-1}}$ 2, 5, 10 iteration of update}

\multiplot{3}{iwf,iwf5,iwf10}{width=0.48\columnwidth}{$\mathbf{W_f^{-1}}$ 2, 5, 10 iteration of update}

%

Subsequently, we used chain weights to perform poststack deconvolution as prescribed in equation (\ref{lsmig}). The result (Figure \ref{fig:decon2,decon5,decon10})shows an immediate improvement in resolution improvement over the initial RTM image. The deconvolved image with 5 iterations has higher resolution compared to the one run with 2 iterations. However, the image with 5 iterations gives a smoother image. This may be from the the fact that we get smoother freqeuncy weight $\mathbf{Wf^{-1]}}$.

\multiplot{3}{decon2,decon5,decon10}{width=0.48\columnwidth}{Poststack Deconvolution Image 2, 5, 10 iteration of update}

%
%

\subsection*{Chain as a Deconvolution Filter: Real Viking Graben data}
\inputdir{../chapter-lsrtm/vk}

In this experiment, we compare the result of using the chain of operator as a deconvolution filter applied to a zero-offset migrated image as in (\ref{lsmig}) with the traditional zero-offset least-square migration. The zero-offset data (Fig \ref{fig:zodata}) comes from the Viking Graben Field. Its corresponding migration velocity is in (\ref{fig:veldix}). We migrated the data using zero-offset RTM. Noted that in the zero-offset data, we have area that we muted during the pre-processing i.e.the area above 0.4s in data domain. Thus, the migrated image will have muted area in depth domain near the surface too.The experiment shows that if we solve for W, Wf using whole stack, the result after applied deconvolution operator will have high frequency artifacts in the area where the data was muted originally.

\plot{zodata}{width=0.6\columnwidth}{Zero-offset shot Viking Graben}
\plot{veldix}{width=0.5\columnwidth}{Dix Velocity for Migration}

%
Hence, we will test the effectiveness of deconvolution filter only the area where we have completed image. In other words, the weights are solved using input two windowed stacks of the first and second migrated image. In Fig \ref{fig:cmig1}, \ref{fig:cdecon}, \ref{fig:lsm0} we show windowed section of the migrated image, deconvolved image by chain weights, and traditional iterative least-square migration repectively. Noted that the amplitude range of deconvolutioned image and LSM image are about the same while that of standard migrated image is in different range.  

\multiplot{3}{cmig1,cdecon,lsm0}{width=0.35\columnwidth}{(left) standard Zero-offset migration (mid) Deconvolved image by chain (right) Iterative LSM}


Fig \ref{fig:zooms} shows the zoom-in portion of these images. We can see that the layers in deconvolutioned image looks more similar to LSM image.

\plot{zooms}{width=1.0\columnwidth}{Zoom-in comparison Viking Graben}

In Fig \ref{fig:vkspec}, deconvolution by chain can recover high frequency but not as good as iterative LSM, which has higher computational cost. The the pattern of frequency spectrum of deconvolved image by chain and that of iterative LSM appear similar which suggests that the chain deconvolution filter derived from the chain emulates the inverse Hessian estimated by iterative LSM.

\plot{vkspec}{width=0.5\columnwidth}{Frequency spectrum of - blue: standard ZORTM, red: Deconvolved by chain, pink: Iterative LSM}



%
%
\newpage
\section{Pre-stack Experiments}
\subsection{Chain as a Preconditioner for Least-square RTM}
\inputdir{../chapter-lsrtm/pre}

We use the weights in Figure \ref{fig:iw,iw5,iw10} and \ref{fig:iwf,iwf5,iwf10}) to form a preconditioner according to equation (\ref{prec}). We chose the weights after 2 update iterations. In Figure \ref{fig:conj}, we show the change made to the generic conjugate-gradient algorithms to incorporate the preconditioning matrix $\mathbf{P}$ according to equation \ref{prec}. The operator $\mathbf{L}$ and $\mathbf{L^T}$ can be any modeling/migration pair. In this case, we use Reverse-Time Migration (RTM). The illustration is modified from \cite[]{madagascar}.

\plot{conj}{width=1.0\columnwidth}{Changes in Conjugate-gradient algorithms to incorporate preconditioner}

We perform least-square reverse time migration using conjugate gradients for 20 iterations. The result without and without preconditioner is shown in Figure. The LSRTM image with precondtioner leads to a noticeable improvement in resolution. The amplitudes appear more balance, and the reflectors at greater depth are better illuminated. 

\multiplot{2}{cgrad20,pgrad20}{width=0.45\columnwidth}{LSRTM Image without (left) and with (left) Preconditioner after 20 iterations}

%

The resolution improvement can be verified by examining the average frequency spectrum of each image (Figure \ref{fig:spec}). LSRTM with preconditioner (pink curve) has the broadest bandwidth compared to LSRTM without preconditioner (red curve) and RTM image (blue curve). 


\plot{spec}{width=0.5\columnwidth}{Frequency spectrum of migrated image - blue: standard RTM, red: LSRTM, pink: Precondition LSRTM}

%

For closer inspection, the selected zoom-in sections are also provided in Figures \ref{fig:zm1},\ref{fig:zm2},\ref{fig:zm3},\ref{fig:zm4}

\plot{zm1}{width=0.7\columnwidth}{Zoom-in comparison 1}
\plot{zm2}{width=0.7\columnwidth}{Zoom-in comparison 2}
\plot{zm3}{width=0.7\columnwidth}{Zoom-in comparison 3}
\plot{zm4}{width=1.0\columnwidth}{Zoom-in comparison 4}

%

Subsequently, we run LSRTM for 100 iterations. The misfit in data domain (Figure \ref{fig:dres100}) is calculated using the $L_2$-norm of data residual $\mathbf{|| d_k - d ||_{2}}$ normalized by $\mathbf{||d ||_{2}}$. It confirms that the chain preconditioner leads to faster convergence. The LSRTM images after 100 iteration are shown in Figures \ref{fig:cgrad100,pgrad100,wwpgrad100}. 

\plot{dres100}{width=0.5\columnwidth}{Normalize data misfit dash=without preconditioner solid(green)=with weight in space only solid(purple)=with chain preconditioner}


\multiplot{3}{cgrad100,pgrad100,wwpgrad100}{width=0.45\columnwidth}{(left)LSRTM Image without Precondtitioner (mid) with Preconditioner ($\mathbf{W}$,$\mathbf{Wf}$) (right) Preconditioner ($\mathbf{W}$ only )after 100 iterations }


In terms of amplitude balancing, LSRTM without preconditioner after 100 iterations gives similar image to the image from LSRTM with precondtioner after only 20 iterations.
